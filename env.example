# Environment variables for the marketing project
# Copy this file to .env and fill in your values

# ============================================================================
# Project Configuration
# ============================================================================
PROJECT_NAME=marketing-project
PROJECT_VERSION=0.1.0

# ============================================================================
# API Keys (REQUIRED for AI features)
# ============================================================================
# OpenAI API key is required for AI-powered content processing
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_key_here

# ============================================================================
# Server Configuration
# ============================================================================
HOST=0.0.0.0
PORT=8000
DEBUG=false

# ============================================================================
# Logging Configuration
# ============================================================================
# All logs go to stdout/stderr for Docker container logging
# Set log level to control verbosity (DEBUG, INFO, WARNING, ERROR, CRITICAL)
MARKETING_PROJECT_LOG_LEVEL=INFO
# Uvicorn/FastAPI log level
LOG_LEVEL=INFO

# ============================================================================
# Content Source Configuration
# ============================================================================
# File sources (enabled by default)
CONTENT_DIR=content/
DATA_DIR=data/

# API sources (optional)
CONTENT_API_URL=https://api.example.com
CONTENT_API_KEY=your_api_key_here

# Database sources (optional for content storage)
CONTENT_DATABASE_URL=sqlite:///./content.db
# For PostgreSQL: postgresql://user:password@localhost:5432/content_db
# For MySQL: mysql://user:password@localhost:3306/content_db
# For MongoDB: mongodb://localhost:27017/content_db

# Main application database (PostgreSQL) - REQUIRED for configuration persistence
# This database stores approval settings, design kit config, and internal docs config
# If not provided, PostgreSQL service will be created in docker-compose
DATABASE_URL=postgresql://postgres:password@localhost:5432/marketing_project
# Alternative: Use POSTGRES_URL as fallback
# POSTGRES_URL=postgresql://postgres:password@localhost:5432/marketing_project

# Individual database connection strings (for content sources)
# MongoDB is optional
MONGODB_URL=mongodb://localhost:27017/marketing_project

# REDIS is REQUIRED for Phase 2+ (job management and ARQ worker queue)
# Use REDIS_URL for simple connection, OR use individual REDIS_HOST/PORT/DATABASE below
REDIS_URL=redis://localhost:6379

# Web scraping sources (optional)
SCRAPE_URLS=https://example.com/blog,https://news.example.com
SCRAPE_DELAY=1.0
SCRAPE_MAX_PAGES=10

# Content source polling
CONTENT_POLLING_ENABLED=true
CONTENT_POLLING_INTERVAL=300
CONTENT_BATCH_SIZE=10

# Content caching
CONTENT_CACHE_ENABLED=true
CONTENT_CACHE_TTL=300
CONTENT_CACHE_MAX_SIZE=1000

# Content Processing
MAX_CONTENT_LENGTH=1000000
CONTENT_BATCH_SIZE=10
CONTENT_TYPES=transcript,blog_post,release_notes
DEFAULT_LANGUAGE=en
SUPPORTED_LANGUAGES=en,es,fr,de

# Template Configuration
TEMPLATE_VERSION=v1
PROMPTS_DIR=src/marketing_project/prompts
PIPELINE_CONFIG_PATH=src/marketing_project/config/pipeline.yml

# File Upload Configuration
UPLOAD_ENABLED=true
UPLOAD_MAX_SIZE=10485760
UPLOAD_ALLOWED_TYPES=text/plain,text/html,text/markdown,application/json,image/jpeg,image/png,image/gif,application/pdf
UPLOAD_DIR=uploads

# ============================================================================
# Phase 2: Redis Configuration (REQUIRED)
# ============================================================================
# Redis is REQUIRED for:
#   - ARQ background job queue
#   - Job state persistence across API/worker restarts
#   - Distributed job management across multiple instances
#   - Analytics caching
#   - Configuration storage (design kit, internal docs, approvals)
#
# Connection options:
#   Option 1: Use REDIS_URL (simple, single connection string)
#     Example: redis://localhost:6379
#   Option 2: Use individual REDIS_HOST, REDIS_PORT, REDIS_DATABASE (more control)
#
# Redis connection (individual settings - preferred for Docker/K8s)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DATABASE=0
# REDIS_PASSWORD=  # Optional Redis password (not used in local development)

# Redis connection pool configuration (for centralized RedisManager)
# These settings control connection pooling, timeouts, and resilience
REDIS_MAX_CONNECTIONS=50
REDIS_SOCKET_TIMEOUT=5.0
REDIS_CONNECT_TIMEOUT=5.0

# Redis health check configuration
# Timeout for health check ping operations (should be shorter than socket timeout)
# For production ElastiCache, consider increasing to 5.0-10.0 if experiencing timeouts
REDIS_HEALTH_CHECK_TIMEOUT=3.0

# Redis retry configuration
# Controls automatic retry behavior for transient failures
REDIS_RETRY_ATTEMPTS=3
REDIS_RETRY_BACKOFF_MIN=2
REDIS_RETRY_BACKOFF_MAX=10

# Circuit breaker configuration
# Prevents cascading failures when Redis is unavailable
REDIS_CIRCUIT_FAILURE_THRESHOLD=5
REDIS_CIRCUIT_RECOVERY_TIMEOUT=60

# CloudWatch metrics (AWS production only)
# Set to 'true' to enable CloudWatch metrics publishing for Redis operations
ENABLE_CLOUDWATCH_METRICS=false
# AWS_REGION is automatically detected in AWS environments

# ============================================================================
# ARQ Worker Configuration (REQUIRED for background jobs)
# ============================================================================
# Number of worker instances to run (affects concurrency and throughput)
# Recommended: 2-4 workers for production, 1-2 for development
ARQ_WORKER_COUNT=2

# Maximum concurrent jobs per worker
# Adjust based on job complexity and available resources
ARQ_MAX_JOBS=10

# Job timeout in seconds (10 minutes default)
# Increase for long-running jobs
ARQ_JOB_TIMEOUT=600

# Job retention settings (Phase 2)
# Jobs are now stored in PostgreSQL database for permanent persistence.
# Redis is used only for active job tracking and ARQ queue coordination.
#
# Redis TTL for active job tracking (jobs are primarily in database):
# Default: 86400 (24 hours) - only for active jobs in Redis cache
# JOB_REDIS_TTL=86400

# Maximum age for jobs before cleanup (in seconds)
# Default: 3600 (1 hour) - used for detecting expired ARQ jobs
# JOB_MAX_AGE=3600

# ============================================================================
# Development Configuration
# ============================================================================
DEV_MODE=false
DEV_RELOAD=false
DEV_DEBUG=false
DEV_PROFILING=false

# ============================================================================
# CORS Configuration (for frontend integration)
# ============================================================================
# Comma-separated list of allowed origins for CORS
# If not set, defaults to regex pattern matching any localhost/127.0.0.1 port
# Examples:
#   CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000
#   CORS_ORIGINS=https://yourdomain.com,https://app.yourdomain.com
# Leave empty/unset for development to allow any localhost port (regex pattern)
# CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Enable localhost regex pattern (default: true)
# When true and CORS_ORIGINS is not set, allows any localhost/127.0.0.1 port
# This is useful for development when frontend ports may vary
# Set to false to disable regex and use explicit origins only
CORS_ALLOW_LOCALHOST_REGEX=true

# Allow credentials in CORS requests (default: true)
CORS_ALLOW_CREDENTIALS=true

# ============================================================================
# Telemetry / OpenInference Configuration (Optional)
# ============================================================================
# OpenInference telemetry for LLM observability and monitoring
# See: https://github.com/Arize-ai/openinference/tree/main/python/instrumentation
#
# Export Configuration:
#   - Set OTEL_EXPORT_CONSOLE=true to export spans to console (stdout/stderr)
#     This is useful for local development - spans will appear in Docker logs
#   - Set ARTHUR_API_KEY and ARTHUR_TASK_ID to export to Arthur AI Platform
#   - You can enable both console and Arthur export simultaneously
#
# Console export (for local development / Docker logs)
# OTEL_EXPORT_CONSOLE=true  # Set to "true" to enable console export
#
# Arthur AI Platform configuration (optional - required only if not using console export)
# ARTHUR_BASE_URL=http://localhost:3030
# ARTHUR_API_KEY=your_arthur_api_key_here
# ARTHUR_TASK_ID=your_arthur_task_id_here
#
# OpenTelemetry standard environment variables (optional)
# OTEL_SERVICE_NAME=marketing-tool  # Service name for tracing (default: "marketing-tool")
# OTEL_DEPLOYMENT_ENVIRONMENT=production  # Deployment environment (default: "production")
# OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=true  # Capture message content (default: "true")
#
# Legacy service name (fallback if OTEL_SERVICE_NAME not set)
# SERVICE_NAME=marketing-tool
