"""
Helper functions for integrating approval flow into processors.

This module provides utilities to pause processing for human approval
of non-deterministic agent outputs.
"""

import json
import logging
from typing import Any, Dict, Optional

from marketing_project.services.approval_manager import get_approval_manager

logger = logging.getLogger(__name__)


class ApprovalRequiredException(Exception):
    """
    Exception raised when approval is required and pipeline should stop.

    This signals that the pipeline should complete the current job and wait
    for user approval before continuing.
    """

    def __init__(self, approval_id: str, job_id: str, step_name: str, step_number: int):
        self.approval_id = approval_id
        self.job_id = job_id
        self.step_name = step_name
        self.step_number = step_number
        super().__init__(
            f"Approval required for step {step_number}: {step_name} (approval_id: {approval_id})"
        )


async def check_and_create_approval_request(
    job_id: str,
    agent_name: str,
    step_name: str,
    step_number: int,
    input_data: Dict[str, Any],
    output_data: Dict[str, Any],
    context: Dict[str, Any],
    confidence_score: Optional[float] = None,
    suggestions: Optional[list] = None,
) -> bool:
    """
    Check if approval is needed and create approval request if required.

    This function:
    1. Checks if approvals are enabled
    2. Checks if this agent requires approval
    3. Creates an approval request if needed
    4. Saves pipeline context to Redis
    5. Raises ApprovalRequiredException to signal pipeline should stop

    Args:
        job_id: ID of the processing job
        agent_name: Name of the agent that generated output
        step_name: Pipeline step name
        step_number: Step number in pipeline
        input_data: Input provided to the agent
        output_data: Output generated by the agent
        context: Accumulated context from previous pipeline steps
        confidence_score: Optional confidence score (0-1)
        suggestions: Optional suggestions for reviewer

    Returns:
        False if no approval needed (pipeline should continue)

    Raises:
        ApprovalRequiredException: If approval is required (pipeline should stop)
    """
    manager = await get_approval_manager(reload_from_db=True)
    settings = manager.settings

    # Check if approvals are enabled
    if not settings.require_approval:
        logger.info(
            f"[APPROVAL] Approvals disabled globally, skipping approval check for {agent_name} in job {job_id}"
        )
        return False

    # Check if this agent requires approval
    logger.info(
        f"[APPROVAL] Checking if {agent_name} requires approval. Enabled agents: {settings.approval_agents}, require_approval={settings.require_approval}"
    )
    if agent_name not in settings.approval_agents:
        logger.warning(
            f"[APPROVAL] Agent '{agent_name}' not in approval_agents list ({settings.approval_agents}), skipping approval. "
            f"To enable approvals for this step, add '{agent_name}' to the approval_agents list in settings."
        )
        return False

    logger.info(
        f"[APPROVAL] Agent '{agent_name}' requires approval, creating approval request for job {job_id}..."
    )

    # Create approval request
    approval = await manager.create_approval_request(
        job_id=job_id,
        agent_name=agent_name,
        step_name=step_name,
        input_data=input_data,
        output_data=output_data,
        confidence_score=confidence_score,
        suggestions=suggestions,
        pipeline_step=agent_name,
    )

    logger.info(
        f"[APPROVAL] Created approval request {approval.id} for agent '{agent_name}' (step: {step_name}) in job {job_id}"
    )

    # If auto-approved, return False to continue
    if approval.status == "approved":
        logger.info(f"Approval {approval.id} auto-approved, continuing pipeline")
        return False

    logger.info(
        f"[APPROVAL] Created approval request {approval.id} for {agent_name} in job {job_id}. "
        f"Pipeline will stop and wait for approval."
    )

    # Save pipeline context to Redis for resume
    # Extract original content from input_data if available
    original_content = input_data.get("original_content") or context.get(
        "input_content"
    )
    await manager.save_pipeline_context(
        job_id=job_id,
        context=context,
        step_name=step_name,
        step_number=step_number,
        step_result=output_data,
        original_content=original_content,
    )

    # Raise exception to signal pipeline should stop
    raise ApprovalRequiredException(
        approval_id=approval.id,
        job_id=job_id,
        step_name=step_name,
        step_number=step_number,
    )


def extract_confidence_score(agent_output: Any) -> Optional[float]:
    """
    Extract confidence score from agent output if available.

    Many LLM agents return confidence scores in their responses.
    This function attempts to extract them from various formats.

    Args:
        agent_output: Agent output (dict, str, or other)

    Returns:
        Confidence score (0-1) if found, None otherwise
    """
    if isinstance(agent_output, dict):
        # Check common keys
        for key in ["confidence", "confidence_score", "score", "certainty"]:
            if key in agent_output:
                try:
                    score = float(agent_output[key])
                    # Normalize to 0-1 if needed
                    if score > 1.0:
                        score = score / 100.0
                    return max(0.0, min(1.0, score))
                except (ValueError, TypeError):
                    pass

    return None


def prepare_approval_data(
    input_content: Any, output_content: Any, max_length: int = 5000
) -> tuple[Dict[str, Any], Dict[str, Any]]:
    """
    Prepare input and output data for approval display.

    Truncates long content and converts to JSON-serializable format.

    Args:
        input_content: Input content (any type)
        output_content: Output content (any type)
        max_length: Maximum length for string fields

    Returns:
        Tuple of (input_data, output_data) as dicts
    """

    def prepare_dict(data: Any) -> Dict[str, Any]:
        if isinstance(data, dict):
            return {
                k: (
                    v[:max_length] + "..."
                    if isinstance(v, str) and len(v) > max_length
                    else v
                )
                for k, v in data.items()
            }
        elif isinstance(data, str):
            content = data[:max_length] + "..." if len(data) > max_length else data
            return {"content": content}
        else:
            try:
                return {"content": str(data)}
            except Exception:
                return {"content": "<Unable to serialize>"}

    return prepare_dict(input_content), prepare_dict(output_content)
