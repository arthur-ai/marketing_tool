{
  "id": "19cba163-3a82-4bd5-974c-8d47fc42dad4",
  "title": "c80b9090-d988-4917-8ec4-137cfb2b2597_ian-pranav-adf-blog-content-input-transcript",
  "content": "\nMeeting created at: 7th Nov, 2025 - 9:00 AM1\n39\n00:02:12,730 --> 00:02:15,570\nPranav Shikarpur: You're the expert on the agent development flywheel.\n\n40\n00:02:15,570 --> 00:02:17,530\nPranav Shikarpur: You built it with upsolve.\n\n41\n00:02:18,250 --> 00:02:27,210\nPranav Shikarpur: And so I kind of want to ask you a bunch of questions and you kind of explain what it is, why it's important, how, what the different cases are, how you get implemented.\n\n42\n00:02:28,410 --> 00:02:36,410\nPranav Shikarpur: And I want to basically take a recording of this and use it, work with an LLM to generate a blog poster.\n\n43\n00:02:37,340 --> 00:02:37,580\nPranav Shikarpur: So.\n\n44\n00:02:38,300 --> 00:02:40,060\nPranav Shikarpur: So that's the whole point of this exercise.\n\n45\n00:02:40,380 --> 00:02:42,220\nPranav Shikarpur: So I know Fireflies is taking notes.\n\n46\n00:02:42,220 --> 00:02:45,180\nPranav Shikarpur: I might also just record it just in case I don't lose it.\n\n47\n00:02:45,740 --> 00:02:47,020\nPranav Shikarpur: So I'll start one.\n\n48\n00:02:50,140 --> 00:02:50,780\nPranav Shikarpur: Awesome.\n\n49\n00:02:52,459 --> 00:03:00,540\nPranav Shikarpur: So, yeah, the way it's going to work is I'll probably ask you a bunch of questions if you could like, go in as much detail as you want.\n\n50\n00:03:00,940 --> 00:03:01,820\nPranav Shikarpur: The more the better.\n\n51\n00:03:02,960 --> 00:03:04,320\nPranav Shikarpur: And we.\n\n52\n00:03:04,480 --> 00:03:04,840\nPranav Shikarpur: So.\n\n53\n00:03:04,840 --> 00:03:05,600\nPranav Shikarpur: So, yeah, so.\n\n54\n00:03:05,760 --> 00:03:13,360\nPranav Shikarpur: So I guess to start off, we're talking about the agent development Flywheel today, right?\n\n55\n00:03:13,680 --> 00:03:18,800\nPranav Shikarpur: That is a part of the ADLC or the agent development life cycle.\n\n56\n00:03:20,960 --> 00:03:28,400\nPranav Shikarpur: Firstly, my question is like, why should like, why is this important?\n\n57\n00:03:28,550 --> 00:03:28,790\nPranav Shikarpur: Important?\n\n58\n00:03:29,510 --> 00:03:40,070\nPranav Shikarpur: If you could explain like, what the agent development flywheel is and like, why I should even consider it if building it for my like, AI products.\n\n59\n00:03:41,110 --> 00:03:48,910\nPranav Shikarpur: If you could explain it to me like I'm five or like I'm, you know, kind of just getting into technology and kind of have a sense of building traditional software.\n\n60\n00:03:48,910 --> 00:03:50,470\nPranav Shikarpur: Yeah, yeah.\n\n61\n00:03:51,270 --> 00:03:52,750\nIan McGraw: To Explain just the flywheel.\n\n62\n00:03:52,750 --> 00:04:03,300\nIan McGraw: I think it probably makes sense to take a step back and explain the need for the whole adlc as like one concept.\n\n63\n00:04:04,740 --> 00:04:23,460\nIan McGraw: And the explain like M5 version is essentially that LLM and AI based applications are a paradigm shift from the normal type of application because they are non deterministic.\n\n64\n00:04:24,290 --> 00:04:31,410\nIan McGraw: Which for the explain like I'm five essentially means you might do the same thing twice and get different results.\n\n65\n00:04:32,050 --> 00:04:32,650\nPranav Shikarpur: Gotcha.\n\n66\n00:04:32,650 --> 00:04:33,130\nPranav Shikarpur: Gotcha.\n\n67\n00:04:33,130 --> 00:04:49,010\nIan McGraw: So for traditional product builders just writing plugging normal code, you can expect that you test the system once and that case will always produce the same results no matter when or who does it.\n\n68\n00:04:49,730 --> 00:04:50,290\nIan McGraw: So it's very.\n\n69\n00:04:50,610 --> 00:05:17,740\nIan McGraw: Well, I won't say it's very easy to test, but it is much easier to test and reason about traditional products and applications that are non that are deterministic because you can guarantee up front that all of your must have features or product aspects are tested and covered so that when you ship to production, you know all the scenarios you covered in your testing will work correctly for customers in production.\n\n70\n00:05:19,500 --> 00:05:20,140\nIan McGraw: This is.\n\n71\n00:05:20,460 --> 00:05:21,220\nPranav Shikarpur: Yeah, go on.\n\n72\n00:05:21,220 --> 00:05:21,660\nPranav Shikarpur: Sorry.\n\n73\n00:05:21,820 --> 00:05:24,060\nIan McGraw: Oh, you can interrupt me, go ahead.\n\n74\n00:05:24,300 --> 00:05:25,300\nPranav Shikarpur: No, I was just wondering.\n\n75\n00:05:25,300 --> 00:05:36,060\nPranav Shikarpur: So is, would you compare some part of this agent development flywheel actually like why don't we just jump into like what the agent development flywheel is.\n\n76\n00:05:36,460 --> 00:05:36,980\nPranav Shikarpur: Yep.\n\n77\n00:05:36,980 --> 00:05:39,140\nIan McGraw: So that's where I was gonna go next.\n\n78\n00:05:39,140 --> 00:05:55,350\nIan McGraw: Which because LLM based applications are inherently non deterministic, the way you build, test and think about the systems and these products built on LLMs is requires a different mindset and approach.\n\n79\n00:05:56,790 --> 00:06:00,630\nIan McGraw: And the reason being is that these systems are non deterministic.\n\n80\n00:06:00,630 --> 00:06:13,680\nIan McGraw: So even though you might test things before you ship them, just because you tested them doesn't mean that the same results will happen when customers run through the same behaviors you tested in production.\n\n81\n00:06:15,280 --> 00:06:31,760\nIan McGraw: So this requires a different mindset to testing, a different mindset to building and a different mindset of, you know, how do I know that my product is ready to ship to production and safe to put in front of users and I can trust that this product is going to do what I tell my customers it's going to do in production.\n\n82\n00:06:32,650 --> 00:06:43,130\nIan McGraw: So we developed this agent development life cycle and the naming is sort of akin to the software development lifecycle, which is that traditional product building aspect.\n\n83\n00:06:44,250 --> 00:06:53,850\nIan McGraw: And the key difference is that rather being than a linear process like software, the agent development process is an iterative and experimentive.\n\n84\n00:06:54,330 --> 00:07:04,530\nIan McGraw: Experimentive, I don't know if that's a word, but experimental process meaning building an agent based product is rather than like traditional software.\n\n85\n00:07:04,530 --> 00:07:06,370\nIan McGraw: When you build it you add features, you ship.\n\n86\n00:07:06,850 --> 00:07:12,130\nIan McGraw: Building a agent based system is a, requires experimentation and optimization.\n\n87\n00:07:12,210 --> 00:07:16,450\nIan McGraw: So it's an optimization process rather than like a linear feature building process.\n\n88\n00:07:18,130 --> 00:07:19,010\nIan McGraw: I'll pause there.\n\n89\n00:07:19,650 --> 00:07:22,090\nIan McGraw: Is there anywhere you want me to go into next?\n\n90\n00:07:22,090 --> 00:07:23,250\nIan McGraw: That's kind of the high level.\n\n91\n00:07:24,830 --> 00:07:25,070\nPranav Shikarpur: Yeah.\n\n92\n00:07:25,070 --> 00:07:37,390\nPranav Shikarpur: You could, if you could go like deeper into like the four stages of the flywheel and why it's important and how you like start thinking about it, that would be great.\n\n93\n00:07:37,710 --> 00:07:38,110\nIan McGraw: Sure.\n\n94\n00:07:39,790 --> 00:07:44,110\nIan McGraw: I think in the latest iteration of the diagrams, we've condensed them down into three.\n\n95\n00:07:44,190 --> 00:07:45,470\nIan McGraw: Is that correct?\n\n96\n00:07:45,950 --> 00:07:46,910\nIan McGraw: The three stages.\n\n97\n00:07:47,870 --> 00:07:51,820\nPranav Shikarpur: Sorry, three stages of ADLC agent development life cycle.\n\n98\n00:07:51,820 --> 00:07:55,540\nPranav Shikarpur: But I think it's four stages in the flywheel.\n\n99\n00:07:55,540 --> 00:07:56,380\nPranav Shikarpur: I can, I can go through.\n\n100\n00:07:56,380 --> 00:07:57,220\nIan McGraw: Oh, I see.\n\n101\n00:07:57,220 --> 00:07:57,500\nIan McGraw: Okay.\n\n102\n00:07:57,500 --> 00:07:58,260\nPranav Shikarpur: Yeah, yeah.\n\n103\n00:07:58,500 --> 00:08:00,060\nIan McGraw: So you want me just to go to the flywheel?\n\n104\n00:08:00,060 --> 00:08:02,260\nPranav Shikarpur: Yeah, no, you can talk about everything.\n\n105\n00:08:02,420 --> 00:08:03,460\nPranav Shikarpur: Yeah, go ahead.\n\n106\n00:08:04,340 --> 00:08:04,820\nPranav Shikarpur: Cool.\n\n107\n00:08:05,300 --> 00:08:22,100\nIan McGraw: So the ADLC models after what has been a pretty standard practice for a long time in what we call traditional machine learning teams, where, you know, you have a data science team that's trying to build a model, train it, you know, do kind of custom in house AI work.\n\n108\n00:08:22,340 --> 00:08:26,780\nIan McGraw: And these teams operated on this premise, you know, that this experimentation process was kind of unknown.\n\n109\n00:08:26,780 --> 00:08:36,419\nIan McGraw: They needed to do iterations and cycles to figure out how to get their AI system from like this untrained to this trained system performing in production.\n\n110\n00:08:36,980 --> 00:08:45,410\nIan McGraw: So taking kind of the lessons from that, we've applied it now to agents and building agent based systems where at a high level there's essentially three phases.\n\n111\n00:08:46,450 --> 00:08:52,690\nIan McGraw: The first phase is more about aligning with business stakeholders than actually building.\n\n112\n00:08:52,690 --> 00:09:01,410\nIan McGraw: And the reason it's important to have this alignment up front is because this is how you're going to evaluate your agent in production to make sure it's meeting your business requirements.\n\n113\n00:09:01,970 --> 00:09:14,860\nIan McGraw: So the first phase is all about, you know, defining what your KPIs are, making sure everyone is on the same page about potential risk tolerance of the agent, you know, like what is the bar for considered safe mean.\n\n114\n00:09:15,740 --> 00:09:28,540\nIan McGraw: And then the final part of phase one is actually building a like prototype version of your agent that you can interact with and start to I guess put trial users on and see, get feedback with.\n\n115\n00:09:30,140 --> 00:09:38,270\nIan McGraw: So the second phase then I think is what you're asking a lot about, which is the flywheel and actually don't have the diagram in front of me.\n\n116\n00:09:38,270 --> 00:09:39,270\nIan McGraw: Do you have a link to it?\n\n117\n00:09:39,590 --> 00:09:40,950\nPranav Shikarpur: Yeah, I got you.\n\n118\n00:09:41,510 --> 00:09:42,390\nPranav Shikarpur: Let me share.\n\n119\n00:09:42,390 --> 00:09:45,110\nPranav Shikarpur: I could probably share my screen if that's easier.\n\n120\n00:09:45,830 --> 00:09:46,630\nPranav Shikarpur: There we go.\n\n121\n00:09:49,750 --> 00:09:52,470\nIan McGraw: Yeah, I'm trying to remember the four subfaces okay.\n\n122\n00:09:57,670 --> 00:09:58,870\nPranav Shikarpur: Okay, cool.\n\n123\n00:10:01,030 --> 00:10:17,980\nIan McGraw: So the whole crux of the flywheel end is how you take essentially this prototype agent you've built in the first phase and initial implementation and get it to an optimized, battle tested agent that you can ship to customers, put in front of like, you know, mission critical situations and things like that.\n\n124\n00:10:18,700 --> 00:10:24,380\nIan McGraw: And the way it works is essentially using those KPIs you define in the first phase.\n\n125\n00:10:26,140 --> 00:10:38,200\nIan McGraw: The crucial part is that you need to transition your teams from sort of this vibe checking approach to a systemated automated approach where all of the agent evaluations are done programmatically.\n\n126\n00:10:39,240 --> 00:10:46,360\nIan McGraw: And the point of this is that you start to build up essentially coverage as you go through this flywheel of more and more cases.\n\n127\n00:10:46,440 --> 00:10:51,640\nIan McGraw: You can be sure you know your agents covering all of the different ways users might interact with it.\n\n128\n00:10:52,520 --> 00:10:58,040\nIan McGraw: So the first step of starting the flywheel is you need some sort of usage to start judging your agent on.\n\n129\n00:10:58,040 --> 00:11:01,290\nIan McGraw: So, you know, this can either be one of three things.\n\n130\n00:11:01,530 --> 00:11:05,610\nIan McGraw: It can be the developers working on the agent, you know, as they're interacting with it, testing it out.\n\n131\n00:11:06,090 --> 00:11:08,170\nIan McGraw: It can be initial pilot customers.\n\n132\n00:11:09,530 --> 00:11:19,130\nIan McGraw: We've also seen people that build another agent and simulate, you know, interacting with their agent using another LLM application just to get some traffic and things like that.\n\n133\n00:11:20,730 --> 00:11:36,450\nIan McGraw: So once you have simulated usage, the next piece is you need to set up and maybe I'm not speaking to this directly as it is in the diagram, but you need to start framing and establishing what your systematic evals are.\n\n134\n00:11:36,850 --> 00:11:41,490\nIan McGraw: So this can look potentially have a variety of different things depending on the agent itself.\n\n135\n00:11:42,770 --> 00:11:49,010\nIan McGraw: Some agents, you know, will focus on prompt evaluations, making sure their prompts are generating the right responses.\n\n136\n00:11:49,490 --> 00:11:55,670\nIan McGraw: Others will focus on tools and making sure their tools have the right input output responses.\n\n137\n00:11:55,670 --> 00:12:10,190\nIan McGraw: And I guess if their tools are non deterministic, centering emails there and then a lot of other agents deal with information retrieval, so rag potentially interacting with databases or some other systems where they're pulling context.\n\n138\n00:12:10,430 --> 00:12:23,070\nIan McGraw: So a third suite of evals we see is often like people making sure that the information the agent's retrieving for given queries is expected and contains all the necessary information so their agent can make the right decisions.\n\n139\n00:12:24,980 --> 00:12:47,780\nIan McGraw: I think there's also a fourth kind of eval, which is then kind of the holistic agent end to end testing evaluation, where you know, you put input into your agent and you can trace through all the decisions the agent's making before it generates its output and then apply eval to sort of the whole process like did the agent Come back with the right response, did it call the right tools in the right order, that sort of thing.\n\n140\n00:12:49,550 --> 00:13:00,430\nIan McGraw: So as part of the flywheel you'll create an initial set of evals, which to start should be focused on your most important KPIs, whether it's like information accuracy, tool accuracy, stuff like that.\n\n141\n00:13:01,310 --> 00:13:06,590\nIan McGraw: You'll then run your simulated or potentially developer usage through your agent as your evals run.\n\n142\n00:13:07,470 --> 00:13:15,800\nIan McGraw: And the important point is then to have statistic and numeric scores that allow you to identify hotspots in your agent's performance.\n\n143\n00:13:16,920 --> 00:13:31,200\nIan McGraw: So for example, if your agent calls, you know, three tools, it might have a text to SQL tool, execute SQL tool, and then like a data analysis tool, you want to make sure you have evals covering each part of those processes.\n\n144\n00:13:31,200 --> 00:13:39,240\nIan McGraw: And then you can score, for example, like the SQL the agent is generating to answer a user's question, gotcha.\n\n145\n00:13:39,800 --> 00:13:49,950\nIan McGraw: So then you know, you can dive into the evals scores and understand like, oh, it looks like you know, half of my evaluations the SQL is not meeting expectations.\n\n146\n00:13:49,950 --> 00:13:54,550\nIan McGraw: So we should probably focus on our text to SQL generation to improve the agent's performance.\n\n147\n00:13:56,630 --> 00:14:03,750\nIan McGraw: So that's the first three cycles usage, identifying failure modes, or excuse me, the first two.\n\n148\n00:14:04,950 --> 00:14:17,540\nIan McGraw: Once you're able to systematically identify failure modes using these evals and like real number measures of performance, the next step then is to start the process back up where you now know where the agent's going wrong.\n\n149\n00:14:17,540 --> 00:14:23,020\nIan McGraw: You need to add new evals to cover those cases, whether that's like good examples, bad examples.\n\n150\n00:14:23,820 --> 00:14:31,580\nIan McGraw: And then the final piece of the flywheel is actually experimenting to figure out how to improve the agent in those negative scenarios.\n\n151\n00:14:32,620 --> 00:14:48,990\nIan McGraw: For example, in the text to SQL case, you know, you need to run experiments, maybe it's prompt tuning, maybe it's using a different model, maybe it's adding more examples to the prompt of somehow empowering the agent to get better at answering SQL questions.\n\n152\n00:14:49,710 --> 00:14:51,470\nIan McGraw: So that is an experimentation process.\n\n153\n00:14:51,470 --> 00:14:52,830\nIan McGraw: You might try a bunch of different things.\n\n154\n00:14:52,830 --> 00:15:00,110\nIan McGraw: You need systematic evals as well there to see which experiments have the best impact on your performance.\n\n155\n00:15:01,710 --> 00:15:02,270\nPranav Shikarpur: Gotcha.\n\n156\n00:15:02,270 --> 00:15:15,480\nIan McGraw: The whole idea is you measure the performance of the live agent, find the failure modes, and then you run experiments to see which of the possible directions you could take addresses the failure modes best.\n\n157\n00:15:15,640 --> 00:15:16,440\nIan McGraw: You identified.\n\n158\n00:15:17,480 --> 00:15:18,760\nPranav Shikarpur: Gotcha, gotcha.\n\n159\n00:15:19,000 --> 00:15:35,410\nIan McGraw: So once you find an improvement, you ship the improvement to production and you start the flywheel again where people are now using the improved version, run the evals, figure out what is now the most significant hotspot, run experiments to improve those and Ship again.\n\n160\n00:15:36,050 --> 00:15:43,010\nIan McGraw: So through this process, you start to build out a greater and greater or bigger and bigger eval suite which covers more and more behaviors.\n\n161\n00:15:43,410 --> 00:15:48,850\nIan McGraw: You also have essentially better and better scores as you're going up this process.\n\n162\n00:15:48,929 --> 00:15:53,890\nIan McGraw: So the idea is to get your agent, you know, like that 99, 100% where it's covering all of your bases.\n\n163\n00:15:54,370 --> 00:16:01,420\nIan McGraw: And you do this through this iteration process and it realistically probably is never going to be complete.\n\n164\n00:16:01,420 --> 00:16:07,820\nIan McGraw: But it's a conversation with business teams about, you know, is 95% good enough?\n\n165\n00:16:07,820 --> 00:16:09,420\nIan McGraw: You know, do we need 99%?\n\n166\n00:16:09,500 --> 00:16:10,700\nIan McGraw: Like, where is that bar?\n\n167\n00:16:10,700 --> 00:16:16,220\nIan McGraw: And how much risk is your business willing tolerate to put this in front of users?\n\n168\n00:16:16,700 --> 00:16:17,340\nPranav Shikarpur: Gotcha.\n\n169\n00:16:17,340 --> 00:16:18,060\nPranav Shikarpur: Gotcha.\n\n170\n00:16:18,300 --> 00:16:19,420\nPranav Shikarpur: Okay, that's awesome.\n\n171\n00:16:19,420 --> 00:16:20,140\nPranav Shikarpur: Yeah, go on.\n\n172\n00:16:20,140 --> 00:16:21,260\nIan McGraw: I was going to say one more point.\n\n173\n00:16:21,260 --> 00:16:31,640\nIan McGraw: I think one of the things that is a benefit for technical teams about this is that it puts them in that conversation and sets them up to have that conversation with the business.\n\n174\n00:16:32,120 --> 00:16:34,280\nIan McGraw: Like, this is a non deterministic thing.\n\n175\n00:16:34,600 --> 00:16:36,840\nIan McGraw: We cannot guarantee the behavior of it.\n\n176\n00:16:37,480 --> 00:16:46,920\nIan McGraw: And putting business in the loop of, you know, we need to have some expectation around, like what happens when things go wrong because it won't be perfect.\n\n177\n00:16:48,440 --> 00:16:56,010\nIan McGraw: So it can set technical teams up so that they are positioned with stakeholders that there's expectations around.\n\n178\n00:16:56,010 --> 00:16:59,130\nIan McGraw: You know, how is this product going to fail and how likely is that case?\n\n179\n00:16:59,130 --> 00:17:06,130\nIan McGraw: So conversations and planning can be done rather than, you know, you shipping an agent to production and then it goes wrong.\n\n180\n00:17:06,130 --> 00:17:08,770\nIan McGraw: And then the business being like, what do you mean it's going wrong?\n\n181\n00:17:08,930 --> 00:17:13,050\nIan McGraw: You know, there's always some chance things will go wrong with non deterministic systems.\n\n182\n00:17:13,050 --> 00:17:19,739\nIan McGraw: So it's important as like a technical team building agents to make sure you're having those conversations.\n\n183\n00:17:20,618 --> 00:17:26,858\nPranav Shikarpur: So this is more of a convince your boss that agent will be reliable.\n\n184\n00:17:27,019 --> 00:17:29,739\nPranav Shikarpur: Like if you follow this process guide.\n\n185\n00:17:30,699 --> 00:17:31,579\nIan McGraw: I think it's both.\n\n186\n00:17:32,059 --> 00:17:38,299\nIan McGraw: If you follow this process, it'll get your agent to like that 99, 100% reliability.\n\n187\n00:17:38,379 --> 00:17:45,740\nIan McGraw: But it also makes you codify, you know, like, what is that bar of reliability mean?\n\n188\n00:17:45,740 --> 00:17:51,860\nIan McGraw: You know, for something like chat gbt, it's probably pretty low because users are just chatting with it.\n\n189\n00:17:51,860 --> 00:17:57,540\nIan McGraw: It's not making, you know, financial decisions or screening resumes or things like that.\n\n190\n00:17:57,540 --> 00:18:08,100\nIan McGraw: Or potentially, you know, I guess ChatGPT now does some agent stuff, but a lot of agents are like investigating JIRA tickets and like handling customer support and issuing refunds.\n\n191\n00:18:08,100 --> 00:18:11,430\nIan McGraw: It's like those agents are much more mission critical that they have to be right.\n\n192\n00:18:11,430 --> 00:18:17,390\nIan McGraw: You don't want to refund someone like accidentally or the wrong amount or stuff like that.\n\n193\n00:18:17,390 --> 00:18:23,110\nIan McGraw: Or there's agents in law, like you can't be making up cases and things like that don't exist.\n\n194\n00:18:23,190 --> 00:18:37,570\nIan McGraw: So it depends on the use case and how the agent's deployed and what the agent is interacting with, about how risk tolerant the agent needs to be or the business needs to accept of the agent for it to be acceptable.\n\n195\n00:18:37,650 --> 00:18:38,690\nIan McGraw: If that makes sense.\n\n196\n00:18:39,010 --> 00:18:39,730\nPranav Shikarpur: That makes sense.\n\n197\n00:18:39,730 --> 00:18:40,450\nPranav Shikarpur: That makes sense.\n\n198\n00:18:40,610 --> 00:18:46,450\nPranav Shikarpur: Now, I've also heard, I mean, I've also, you know, heard and used guardrails.\n\n199\n00:18:46,770 --> 00:18:54,850\nPranav Shikarpur: How much of reliability for an AI agent, or just, you know, a gen product for that matter, is guardrails?\n\n200\n00:18:55,090 --> 00:18:57,370\nPranav Shikarpur: Actually, since we're talking about agents, let's keep it to agents.\n\n201\n00:18:57,370 --> 00:19:04,210\nPranav Shikarpur: But how many, how much of this reliability for agents is Guardrails vs. Evals?\n\n202\n00:19:04,210 --> 00:19:05,770\nPranav Shikarpur: And do they go hand in hand?\n\n203\n00:19:07,290 --> 00:19:08,810\nIan McGraw: I think they go hand in hand.\n\n204\n00:19:08,810 --> 00:19:13,250\nIan McGraw: They're complementary but distinct, I guess.\n\n205\n00:19:13,250 --> 00:19:13,930\nIan McGraw: Strategies.\n\n206\n00:19:14,410 --> 00:19:14,970\nPranav Shikarpur: Okay.\n\n207\n00:19:15,450 --> 00:19:25,610\nIan McGraw: Evals I view as something that is assessing the agent's performance as it runs, but it's not actually changing the agent.\n\n208\n00:19:25,770 --> 00:19:27,290\nIan McGraw: It's purely an assessment.\n\n209\n00:19:28,010 --> 00:19:28,650\nPranav Shikarpur: Gotcha.\n\n210\n00:19:28,650 --> 00:19:46,490\nIan McGraw: Whereas guardrails are in, you know, like you're going down the wrong path or like, you know, like the agent's about to give a response and the guardrail prevents it for this reason.\n\n211\n00:19:46,490 --> 00:19:49,810\nIan McGraw: Like you can't, you know, make a company policy or something.\n\n212\n00:19:49,970 --> 00:19:51,730\nIan McGraw: So I think they're complementary.\n\n213\n00:19:51,730 --> 00:19:58,350\nIan McGraw: I think the guardrails are more around ensuring the agent does or does not do specific things while it's executing.\n\n214\n00:19:58,350 --> 00:20:01,990\nIan McGraw: Where evals are more assessments of how the agent performed.\n\n215\n00:20:03,110 --> 00:20:03,990\nPranav Shikarpur: That makes sense.\n\n216\n00:20:04,310 --> 00:20:05,110\nPranav Shikarpur: That makes sense.\n\n217\n00:20:05,670 --> 00:20:16,950\nPranav Shikarpur: And since we're talking about this agent development life cycle and like kind of saying it's analogous to the software development life cycle, but like, for agents, what would you.\n\n218\n00:20:17,350 --> 00:20:23,180\nPranav Shikarpur: Is there like a part in the STLC process that you'd say is analogous to the flywheel?\n\n219\n00:20:23,340 --> 00:20:24,620\nPranav Shikarpur: Like, would it be CI?\n\n220\n00:20:25,180 --> 00:20:25,900\nPranav Shikarpur: Would it be.\n\n221\n00:20:27,180 --> 00:20:30,780\nPranav Shikarpur: Is there something that you think or you think it's unique in its own way?\n\n222\n00:20:35,820 --> 00:20:42,060\nIan McGraw: I think the flywheel piece of this is what sets it apart from the traditional software lifecycle.\n\n223\n00:20:42,060 --> 00:20:47,580\nIan McGraw: Because I mean, software, you ship and iterate that way.\n\n224\n00:20:47,580 --> 00:20:51,760\nIan McGraw: Like you ship a feature, get feedback, you know, ship tweaks, things like that.\n\n225\n00:20:52,560 --> 00:21:01,360\nIan McGraw: But the actual building of features itself is not iterative investigative experiment process.\n\n226\n00:21:02,240 --> 00:21:10,160\nIan McGraw: Like if I want to build a new API, like I don't need to figure out how to like tune knobs to optimize, you know, that backend endpoint, right.\n\n227\n00:21:10,640 --> 00:21:13,360\nIan McGraw: But it's like, oh, I want my agent to now handle this other use case.\n\n228\n00:21:13,360 --> 00:21:18,640\nIan McGraw: It's like, okay, it's not a straightforward like, oh, I just code these steps and the agent will do it.\n\n229\n00:21:18,980 --> 00:21:23,620\nIan McGraw: It's like we need to figure out the best prompt, we need to figure out the best context to pass the agent.\n\n230\n00:21:23,940 --> 00:21:27,940\nIan McGraw: We need to run all these different trials and see which ones, you know, perform the best.\n\n231\n00:21:28,900 --> 00:21:31,780\nIan McGraw: So that's I think actually the key distinction between the two.\n\n232\n00:21:32,340 --> 00:21:32,980\nPranav Shikarpur: Gotcha.\n\n233\n00:21:33,140 --> 00:21:33,780\nPranav Shikarpur: Gotcha.\n\n234\n00:21:33,780 --> 00:21:54,980\nPranav Shikarpur: Okay, now stepping into, you know, what are the downsides somebody will face by not implementing this iterative cycle of like experimenting and ensuring, getting like performance metrics for your agent.\n\n235\n00:21:57,540 --> 00:22:02,980\nPranav Shikarpur: If you were to think about like, you know, a world where somebody doesn't do this and just, you know, does it without any.\n\n236\n00:22:03,460 --> 00:22:05,380\nPranav Shikarpur: Yeah, I think it kind of goes.\n\n237\n00:22:05,380 --> 00:22:08,660\nIan McGraw: Back to our conversation earlier of like what happens when you do this.\n\n238\n00:22:08,660 --> 00:22:12,190\nIan McGraw: Essentially it's two things, I think maybe three.\n\n239\n00:22:12,350 --> 00:22:22,830\nIan McGraw: But the first two I see is like one, if you just ship five coded agents to production, you're going to impact customers, they're not going to trust it and you're ultimately going to like not be successful.\n\n240\n00:22:23,390 --> 00:22:26,910\nIan McGraw: It's like your product is not going to do what it's supposed to.\n\n241\n00:22:27,550 --> 00:22:42,390\nIan McGraw: I think the second point is then on like the internal business side, you're going to lose trust as a technical team that you are able to ship reliable AI based solutions.\n\n242\n00:22:42,870 --> 00:22:52,590\nIan McGraw: The business won't trust you to deliver on the things you say you're going to deliver because they won't work, customers won't use them, like they won't be trusted.\n\n243\n00:22:52,590 --> 00:22:54,710\nIan McGraw: All of the things you need to have a successful product.\n\n244\n00:22:54,710 --> 00:23:01,720\nIan McGraw: So both external facing with customers and internal facing with like other teams in the company will be impacted.\n\n245\n00:23:03,950 --> 00:23:12,070\nPranav Shikarpur: Yeah, I mean you and I have also heard like a lot of startups are like, oh, like we can do this without any kind of eval metrics or things like that.\n\n246\n00:23:12,070 --> 00:23:17,070\nPranav Shikarpur: And they probably lose trust with their, you know, their early customers or design partners.\n\n247\n00:23:18,110 --> 00:23:25,870\nIan McGraw: It's either they're gonna lose trust or they just like won't get green lighted to go live with like significant organizations.\n\n248\n00:23:25,950 --> 00:23:26,350\nIan McGraw: Right.\n\n249\n00:23:26,590 --> 00:23:46,650\nIan McGraw: It's like so many of these agents are going to go through a review process and customers where they're going to try it out, they're going to test it, know they're gonna be like, oh well you know, I, it couldn't do this step that you said it could do and as a result like I don't want to roll this out to the rest of my org as a business leader because I'm gonna Look like an idiot for buying this software.\n\n250\n00:23:47,850 --> 00:23:48,730\nPranav Shikarpur: That makes sense.\n\n251\n00:23:48,810 --> 00:23:49,690\nPranav Shikarpur: That makes sense.\n\n252\n00:23:49,930 --> 00:23:52,570\nPranav Shikarpur: The green light is like a big thing here, I think.\n\n253\n00:23:52,810 --> 00:24:01,300\nPranav Shikarpur: Yeah, it's like it, the flywheel kind of gives you metrics that allow you to get a green light and AI cool.\n\n254\n00:24:01,300 --> 00:24:02,420\nPranav Shikarpur: Now if somebody is.\n\n255\n00:24:02,420 --> 00:24:04,180\nPranav Shikarpur: Let's, let's say I'm just starting to.\n\n256\n00:24:04,260 --> 00:24:05,300\nPranav Shikarpur: I have an agent.\n\n257\n00:24:05,700 --> 00:24:13,780\nPranav Shikarpur: It does a bunch of tool calls, uses like a bunch of different, like memory and you know, runs on whatever popular framework out there.\n\n258\n00:24:15,380 --> 00:24:16,180\nPranav Shikarpur: What are, what.\n\n259\n00:24:16,180 --> 00:24:22,580\nPranav Shikarpur: Are there any considerations I need to take before starting, you know, getting my baseline metrics out?\n\n260\n00:24:23,300 --> 00:24:29,570\nPranav Shikarpur: Are there any considerations about like, how many tools I'm calling or like how.\n\n261\n00:24:29,730 --> 00:24:31,970\nPranav Shikarpur: How many variables are in play here?\n\n262\n00:24:33,490 --> 00:24:38,210\nPranav Shikarpur: Yeah, it's more pretty, pretty broad in general, but yeah, curious.\n\n263\n00:24:38,370 --> 00:24:39,770\nIan McGraw: So, sorry, what's the question?\n\n264\n00:24:39,770 --> 00:24:40,370\nIan McGraw: Exactly?\n\n265\n00:24:41,010 --> 00:24:42,610\nPranav Shikarpur: Yeah, so the question is like, is there.\n\n266\n00:24:42,610 --> 00:24:55,580\nPranav Shikarpur: And are there any like, considerations I need to be taking before I start getting like, before I start, you know, creating that live and simulated usage and you know, creating that iterated cycle of testing.\n\n267\n00:24:59,100 --> 00:25:00,740\nIan McGraw: In terms of actually building the agent?\n\n268\n00:25:00,740 --> 00:25:14,300\nIan McGraw: I think the main thing, which I realize now, I forgot to mention in the first phase is you need like the initial implementation, you need the KPIs to know what to measure and you also need to make sure you have the ability to observe what it's doing.\n\n269\n00:25:15,020 --> 00:25:31,750\nIan McGraw: So regardless of how many tools or context it is calling to, one of the things he needs to do in the initial implementation is make sure you instrument your agent with what we call it tracing, so that you can see all of the decisions and the steps the agent's doing behind the scenes.\n\n270\n00:25:31,830 --> 00:25:43,190\nIan McGraw: Because without that, you're going to have no ability to debug, no ability to investigate, like when things go off the rails, and no ability to figure out where to start experimenting when your evals fail.\n\n271\n00:25:44,320 --> 00:25:44,880\nPranav Shikarpur: Gotcha.\n\n272\n00:25:46,240 --> 00:25:47,960\nPranav Shikarpur: Would you say there's like a.\n\n273\n00:25:47,960 --> 00:25:54,280\nPranav Shikarpur: So I noticed you mentioned like, you know, picking your evals before you start and like, sorry, picking the, like the metrics that matter to you.\n\n274\n00:25:54,280 --> 00:25:54,480\nPranav Shikarpur: Right.\n\n275\n00:25:54,480 --> 00:25:55,920\nPranav Shikarpur: Or like the KPIs that matter.\n\n276\n00:25:56,960 --> 00:25:59,559\nPranav Shikarpur: Like, is there a way you could like codify that by an example?\n\n277\n00:25:59,559 --> 00:26:06,160\nPranav Shikarpur: Like let's say we have like an E commerce bot, like a customer support chat that gives refunds or like, does like customer support.\n\n278\n00:26:06,960 --> 00:26:08,760\nPranav Shikarpur: Trouble solving.\n\n279\n00:26:08,760 --> 00:26:09,040\nPranav Shikarpur: Right.\n\n280\n00:26:09,040 --> 00:26:14,370\nPranav Shikarpur: So how would you start to define KPIs for an example like that?\n\n281\n00:26:15,490 --> 00:26:22,530\nPranav Shikarpur: And how would you like kind of codify that into what you want to look for in your agent and feel free to make up the architecture and all that stuff?\n\n282\n00:26:23,970 --> 00:26:39,210\nIan McGraw: Yeah, Customer service is pretty generic, but I think a few I would expect is off the top of my head, an alignment with company service policies.\n\n283\n00:26:39,290 --> 00:26:51,369\nIan McGraw: It's kind of a vague concept metric but like you know, how many cases is the agent handling in accordance with like existing customer service guidelines?\n\n284\n00:26:51,369 --> 00:27:03,610\nIan McGraw: So essentially like you know, it should handle a refund in the case that a refund is reasonable or you know, it should route the user to this right action depending on, you know, what they're requesting.\n\n285\n00:27:05,080 --> 00:27:16,280\nIan McGraw: So I would probably create a KPI of like 95% of all customer service flows are handled as a human would or something like that.\n\n286\n00:27:17,720 --> 00:27:20,360\nIan McGraw: In terms of architecture that would I think really depend.\n\n287\n00:27:20,600 --> 00:27:26,560\nIan McGraw: I know a lot of companies that are starting to adopt AI agents for customer service.\n\n288\n00:27:26,560 --> 00:27:33,630\nIan McGraw: At least start with like a less agentic based system because they don't again trust the agent in all cases.\n\n289\n00:27:33,630 --> 00:27:43,390\nIan McGraw: So they'll give you know, like the bottom 15% of the easy to handle things to the agent and then the agent will route to humans for anything more complicated.\n\n290\n00:27:44,430 --> 00:27:59,480\nIan McGraw: So if you're starting an initial implementation, maybe that's a good approach where you know, you identify the low hanging fruit, you pass that off to the agent and then you can use evals to say like for these trivial cases to the agent, know, do the right action.\n\n291\n00:28:01,560 --> 00:28:02,840\nPranav Shikarpur: Gotcha, gotcha.\n\n292\n00:28:03,560 --> 00:28:12,840\nIan McGraw: Trying to think of other KPIs probably something like you know, around the tone of the agent.\n\n293\n00:28:14,600 --> 00:28:22,640\nIan McGraw: Also referencing like trying to think of the word for this but tone of the agent.\n\n294\n00:28:22,640 --> 00:28:24,200\nIan McGraw: But also like the.\n\n295\n00:28:28,030 --> 00:28:28,510\nPranav Shikarpur: You know, I'm.\n\n296\n00:28:28,510 --> 00:28:39,070\nIan McGraw: Like trying to think of like the on topicness of like you shouldn't just like ask a customer support agent like anything, you know, it should be related stuff.\n\n297\n00:28:39,230 --> 00:28:45,830\nPranav Shikarpur: So it's like response relevance but like grounded by like the company policy docs.\n\n298\n00:28:45,830 --> 00:28:46,190\nPranav Shikarpur: Right?\n\n299\n00:28:46,510 --> 00:28:48,150\nPranav Shikarpur: Yeah, gotcha.\n\n300\n00:28:48,150 --> 00:28:54,200\nIan McGraw: I guess you talk about the company, you shouldn't be able to ask it, you know, like chatgpt questions.\n\n301\n00:28:54,520 --> 00:28:55,320\nPranav Shikarpur: Yeah, yeah.\n\n302\n00:28:56,920 --> 00:29:00,920\nIan McGraw: The other thing would be what was I just thinking of?\n\n303\n00:29:07,560 --> 00:29:10,200\nIan McGraw: Or maybe I just said something in my head but not escaping me.\n\n304\n00:29:12,120 --> 00:29:18,440\nIan McGraw: Oh yeah, the ability to like prompt inject it to like get out of its sandbox I think.\n\n305\n00:29:18,690 --> 00:29:28,690\nIan McGraw: I don't know if that's the KPI, but you could definitely set up like an eval suite of like potential prompt injections and make sure your agent is resilient to those.\n\n306\n00:29:30,770 --> 00:29:31,730\nPranav Shikarpur: Okay, gotcha.\n\n307\n00:29:32,850 --> 00:29:44,770\nPranav Shikarpur: And so when you said, you know, like the initial part is you collect a bunch of baseline, you know, data so that you can compare it so you can start running, you know, tests on it.\n\n308\n00:29:47,500 --> 00:29:47,980\nPranav Shikarpur: How much?\n\n309\n00:29:48,300 --> 00:29:55,180\nPranav Shikarpur: Okay, what would you recommend as like a good starting point in your baseline data set?\n\n310\n00:29:55,900 --> 00:29:57,420\nPranav Shikarpur: That's my number one question.\n\n311\n00:29:57,420 --> 00:30:03,420\nPranav Shikarpur: And number two, how important is it to have good and bad cases in your data set?\n\n312\n00:30:03,980 --> 00:30:11,060\nIan McGraw: Yeah, sorry, what was the first part you're asking?\n\n313\n00:30:11,060 --> 00:30:12,940\nIan McGraw: What's important to have in your data set?\n\n314\n00:30:13,460 --> 00:30:17,460\nPranav Shikarpur: Like what's the size of the data set that you recommend to start off with?\n\n315\n00:30:17,460 --> 00:30:17,860\nIan McGraw: Size.\n\n316\n00:30:17,860 --> 00:30:35,980\nIan McGraw: Okay, today we're advising a lot of people to have, you know, under probably 200 rows of their test data sets for the reason that one, you need to often review the results manually to find these hotspots and like investigate why things are going wrong.\n\n317\n00:30:35,980 --> 00:30:39,220\nIan McGraw: So having like 10,000 test cases isn't really going to help you.\n\n318\n00:30:39,850 --> 00:30:54,970\nIan McGraw: It's better to have a good amount of coverage on a few select like well curated tests so that way you can manage them, you can understand why they're failing and then you can more importantly like start to experiment to address the failures.\n\n319\n00:30:56,570 --> 00:30:57,290\nIan McGraw: So size wise.\n\n320\n00:30:57,290 --> 00:30:59,690\nIan McGraw: Yeah, we're recommending like under 200 for now.\n\n321\n00:31:00,730 --> 00:31:06,490\nIan McGraw: To your second question of as good and bad examples.\n\n322\n00:31:06,490 --> 00:31:13,230\nIan McGraw: Yeah, I think for the most part, one data set should probably only have good or only have bad.\n\n323\n00:31:14,510 --> 00:31:20,750\nIan McGraw: The reason being is when you apply evals, you'll want to like judge the contents of the test suite the same.\n\n324\n00:31:22,110 --> 00:31:28,830\nIan McGraw: So like, if you have good and bad examples, you'd need different evals to like assert, you know, this is a bad example.\n\n325\n00:31:28,830 --> 00:31:32,830\nIan McGraw: So like make sure it does not do this versus this is a good example, make sure it does do this.\n\n326\n00:31:34,030 --> 00:31:37,430\nIan McGraw: So I can see value in having a good example and a bad example data set.\n\n327\n00:31:37,430 --> 00:31:43,470\nIan McGraw: Especially because the bad example data set is where you probably will start to identify the failure modes.\n\n328\n00:31:43,790 --> 00:31:46,750\nIan McGraw: Yeah, that tell you how to improve the bad examples.\n\n329\n00:31:47,230 --> 00:31:56,190\nIan McGraw: But for running evals, it's usually like, you know, kind of thinking akin to traditional software testing where you want like these are the test cases it must do well on.\n\n330\n00:31:58,350 --> 00:32:13,890\nIan McGraw: There is a, something we're currently thinking about where you could potentially feed like start to accumulate good and bad examples and then actually feed them into future runs of the agent as additional context.\n\n331\n00:32:14,690 --> 00:32:16,890\nIan McGraw: Okay, something worth.\n\n332\n00:32:16,890 --> 00:32:19,450\nIan McGraw: Yeah, trying to figure out exactly how it could work.\n\n333\n00:32:19,450 --> 00:32:30,020\nIan McGraw: But it may be worth keeping bad examples to then show as examples of bad behavior to the agent in the future so that the agent can learn from its past mistakes.\n\n334\n00:32:31,540 --> 00:32:32,260\nPranav Shikarpur: Gotcha.\n\n335\n00:32:32,260 --> 00:32:34,740\nPranav Shikarpur: Okay, that makes sense.\n\n336\n00:32:34,900 --> 00:32:40,420\nIan McGraw: Less on the evals, but more on like the ability for the agent to adapt and adjust.\n\n337\n00:32:41,540 --> 00:32:42,580\nPranav Shikarpur: Okay, gotcha.\n\n338\n00:32:44,580 --> 00:32:45,460\nPranav Shikarpur: That makes sense.\n\n339\n00:32:45,700 --> 00:32:51,940\nPranav Shikarpur: And okay, so I Guess my next question is.\n\n340\n00:32:54,110 --> 00:33:02,910\nPranav Shikarpur: Okay, so once I've set up a baseline, kind of gotten a metric for, you know, let's say we're doing this.\n\n341\n00:33:03,470 --> 00:33:08,990\nPranav Shikarpur: I, I know this customer service is really weighing, but let's say it has, like, a knowledge base and it calls, like, one tool.\n\n342\n00:33:10,270 --> 00:33:15,630\nPranav Shikarpur: And so I'm kind of like, looking at how grounded the response is one of my metrics.\n\n343\n00:33:15,630 --> 00:33:25,600\nPranav Shikarpur: And the second metric I'm looking at is, like, how, like, I would say it has two tools, and I'm looking at, like, which tool it's like, calling accurately.\n\n344\n00:33:26,080 --> 00:33:26,640\nIan McGraw: Okay.\n\n345\n00:33:28,480 --> 00:33:29,240\nPranav Shikarpur: Like, what is.\n\n346\n00:33:29,240 --> 00:33:31,760\nPranav Shikarpur: What is a good, like, score here?\n\n347\n00:33:31,840 --> 00:33:32,200\nPranav Shikarpur: Right?\n\n348\n00:33:32,200 --> 00:33:33,920\nPranav Shikarpur: Like, is it.\n\n349\n00:33:34,320 --> 00:33:36,720\nPranav Shikarpur: Is it more of, like, you know, like, the more the better.\n\n350\n00:33:36,800 --> 00:33:39,000\nPranav Shikarpur: Like, the closer it is 100, the better?\n\n351\n00:33:39,000 --> 00:33:44,490\nPranav Shikarpur: Or like, is there, like, a metric you recommend after which you're like, you can ship it.\n\n352\n00:33:44,490 --> 00:33:45,370\nPranav Shikarpur: It's green light.\n\n353\n00:33:46,090 --> 00:33:46,650\nIan McGraw: Yeah.\n\n354\n00:33:46,890 --> 00:33:51,850\nIan McGraw: This goes back to phase one, which is all about the KPI alignment with your business team.\n\n355\n00:33:52,170 --> 00:33:55,930\nIan McGraw: Because the reality is probably 100 is impossible.\n\n356\n00:33:56,490 --> 00:34:00,490\nIan McGraw: Yeah, it's never going to be 100% reliable.\n\n357\n00:34:00,490 --> 00:34:04,570\nIan McGraw: But the reality is there's probably some threshold at which it's good enough.\n\n358\n00:34:05,930 --> 00:34:09,850\nIan McGraw: Says that, you know, 80, 90, 95, 99.\n\n359\n00:34:10,609 --> 00:34:18,129\nIan McGraw: that's a conversation to have per agent, per, like, organization.\n\n360\n00:34:19,168 --> 00:34:19,809\nPranav Shikarpur: Gotcha.\n\n361\n00:34:20,688 --> 00:34:22,489\nPranav Shikarpur: Okay, that, that makes sense.\n\n362\n00:34:22,489 --> 00:34:31,248\nPranav Shikarpur: So you're like, align it with the business KPIs more importantly, and you probably want to match that or out compete that if possible, you know?\n\n363\n00:34:31,248 --> 00:34:31,728\nIan McGraw: Yeah.\n\n364\n00:34:31,969 --> 00:34:38,529\nIan McGraw: And then that's why I think the ADLC is a good practice for technical teams is because it forces them to have that conversation.\n\n365\n00:34:38,688 --> 00:34:50,099\nIan McGraw: So rather than you getting blamed or the agent goes off the rails, you know, you have to put that decision on the business team of, like, how comfortable or what is your threshold for mistakes?\n\n366\n00:34:50,579 --> 00:34:55,859\nIan McGraw: And it can't be zero, because that's likely impossible and you might as well not build an agent.\n\n367\n00:34:56,899 --> 00:34:58,179\nPranav Shikarpur: Yeah, yeah.\n\n368\n00:34:58,179 --> 00:34:59,139\nPranav Shikarpur: No, that makes sense.\n\n369\n00:34:59,379 --> 00:35:00,259\nPranav Shikarpur: That makes sense.\n\n370\n00:35:02,179 --> 00:35:02,739\nPranav Shikarpur: Yeah.\n\n371\n00:35:02,899 --> 00:35:03,939\nPranav Shikarpur: My next question is.\n\n372\n00:35:05,150 --> 00:35:21,310\nPranav Shikarpur: So there, depending on, like, the application you're building, whether it's a rag tool or it's like an agentic thing that uses a bunch of tools, or if it's like a different architecture, it calls for different evals.\n\n373\n00:35:21,710 --> 00:35:22,070\nPranav Shikarpur: Right.\n\n374\n00:35:22,070 --> 00:35:43,200\nPranav Shikarpur: Based on the KPIs, the broad KPIs that you're trying to hit, is there a way you could potentially, like, walk through the different use cases that you might have worked in your experience or about, like, you know, the different evals that you think are important to set up in These different architecture use cases.\n\n375\n00:35:45,600 --> 00:35:52,640\nIan McGraw: Like examples of specific evals I've seen or are you thinking more just like different kinds of evals?\n\n376\n00:35:53,120 --> 00:36:01,530\nPranav Shikarpur: Different kinds of evals that you think are important for like you know, a rag setup or like an agent set up with XYZ tools?\n\n377\n00:36:02,490 --> 00:36:06,690\nPranav Shikarpur: Yeah, I know this can be pretty broad depending on like the architecture, but.\n\n378\n00:36:06,690 --> 00:36:12,970\nIan McGraw: Yeah, yeah, I guess starting with rag and generally information retrieval, it's a lot about.\n\n379\n00:36:15,050 --> 00:36:22,570\nIan McGraw: Well, traditionally like you think of Google, right, as a search engine, they're all about both recall but also precision.\n\n380\n00:36:23,450 --> 00:36:28,400\nIan McGraw: Like they don't want, they want the top four or five links to be, you know, exactly what you're looking for.\n\n381\n00:36:29,280 --> 00:36:34,160\nIan McGraw: With agents, it's I think more falling on the recall measure.\n\n382\n00:36:34,160 --> 00:36:37,840\nIan McGraw: So you want to make sure the agent has all relevant information.\n\n383\n00:36:39,280 --> 00:36:43,400\nIan McGraw: If the agent has some extra irrelevant information, it's not that big a deal.\n\n384\n00:36:43,400 --> 00:36:49,120\nIan McGraw: You may end up paying more in token cost but like from the agent's perspective, it's just going to ignore it.\n\n385\n00:36:50,000 --> 00:36:59,760\nIan McGraw: So traditionally I think rag information retrieval is more optimized for making sure there's nothing left out that the agent should have seen.\n\n386\n00:37:00,320 --> 00:37:02,720\nIan McGraw: So that is a lot of evals for recall.\n\n387\n00:37:02,800 --> 00:37:11,360\nIan McGraw: So basically an eval is like if I issue this query to the RAG system, do I get all of this expected context that I want to see?\n\n388\n00:37:12,160 --> 00:37:12,880\nPranav Shikarpur: Gotcha.\n\n389\n00:37:12,880 --> 00:37:21,530\nIan McGraw: So that's a big one because if the agent doesn't have everything, it's going to make the wrong decision or answer incorrectly or things like that.\n\n390\n00:37:21,610 --> 00:37:24,850\nPranav Shikarpur: And when you say recall, you don't mean this in machine learning perspective.\n\n391\n00:37:24,850 --> 00:37:28,010\nPranav Shikarpur: Recall, you mean more of like information retrieval.\n\n392\n00:37:29,370 --> 00:37:34,650\nIan McGraw: It's like, you know, if you're evaluating a class of, or a recommender system, I think.\n\n393\n00:37:34,650 --> 00:37:37,650\nIan McGraw: Yeah, saying recall like precision and recall.\n\n394\n00:37:37,650 --> 00:37:38,410\nPranav Shikarpur: Okay, gotcha.\n\n395\n00:37:38,410 --> 00:37:46,440\nIan McGraw: So it is kind of a machine learning term, but yeah, generally more just like a, a ranked list information retrieval metric.\n\n396\n00:37:47,080 --> 00:37:47,760\nPranav Shikarpur: Gotcha.\n\n397\n00:37:47,760 --> 00:37:48,360\nPranav Shikarpur: Gotcha.\n\n398\n00:37:48,600 --> 00:37:49,160\nPranav Shikarpur: Okay.\n\n399\n00:37:49,800 --> 00:37:56,600\nPranav Shikarpur: So if it's a RAG based system, you want to ensure that all the information is coming back in the context when you're retrieving stuff.\n\n400\n00:37:56,600 --> 00:37:58,840\nPranav Shikarpur: But for an agent it's not that big of a deal.\n\n401\n00:38:01,000 --> 00:38:13,250\nIan McGraw: Yeah, specifically the, if you have too much information or like some extra documents or something, it's not usually a problem unless those documents potentially contradict the right answer.\n\n402\n00:38:13,650 --> 00:38:14,850\nPranav Shikarpur: But that makes sense.\n\n403\n00:38:15,090 --> 00:38:16,450\nIan McGraw: Yeah, so.\n\n404\n00:38:16,450 --> 00:38:24,930\nPranav Shikarpur: So a lot of this we're talking about is like, you know, more like plain texting agent does some plain text retrieval and comparison or tool calls.\n\n405\n00:38:25,330 --> 00:38:27,850\nPranav Shikarpur: What happens when you're like building like.\n\n406\n00:38:27,850 --> 00:38:31,610\nPranav Shikarpur: I mean it's not just developers that Are using agents for like code.\n\n407\n00:38:31,610 --> 00:38:44,120\nPranav Shikarpur: It's like sometimes you also need to, you know, generate charts in your use case or like, sometimes you need like to do some like logic in the agent using some generative like, you know, code generation.\n\n408\n00:38:44,200 --> 00:38:46,760\nPranav Shikarpur: So how do you think about that?\n\n409\n00:38:46,760 --> 00:38:49,399\nPranav Shikarpur: You know, that's like slightly different from plain text, you know.\n\n410\n00:38:49,399 --> 00:38:52,240\nPranav Shikarpur: So how do you start to build evals there?\n\n411\n00:38:52,240 --> 00:38:53,080\nPranav Shikarpur: Is it similar?\n\n412\n00:38:53,320 --> 00:38:54,280\nPranav Shikarpur: Are there differences?\n\n413\n00:38:56,040 --> 00:39:04,370\nIan McGraw: Yeah, I guess it would probably depend more on like what specific tasks the agent is doing.\n\n414\n00:39:05,170 --> 00:39:11,410\nIan McGraw: Because evals are so specific, it's a little hard to just be like, oh, if my agent's writing code to solve something, like what eval would I use?\n\n415\n00:39:11,730 --> 00:39:12,210\nPranav Shikarpur: Yeah.\n\n416\n00:39:14,050 --> 00:39:15,610\nIan McGraw: I mean there's some basic evals.\n\n417\n00:39:15,610 --> 00:39:20,850\nIan McGraw: Like if your agent's writing Python code, like does it, you know, is it syntactically correct?\n\n418\n00:39:22,130 --> 00:39:22,930\nIan McGraw: Does it run?\n\n419\n00:39:24,610 --> 00:39:29,700\nIan McGraw: There's probably business level KPIs of like, does it return the answer?\n\n420\n00:39:29,700 --> 00:39:32,300\nIan McGraw: I would expect or format I expect.\n\n421\n00:39:35,020 --> 00:39:43,420\nIan McGraw: It is an interesting problem to start to figure out how to assess like the.\n\n422\n00:39:43,420 --> 00:39:44,700\nIan McGraw: I guess we didn't talk about this yet.\n\n423\n00:39:44,700 --> 00:39:47,140\nIan McGraw: There's like two domains of evals I'm thinking of.\n\n424\n00:39:47,140 --> 00:39:57,670\nIan McGraw: There's kind of like the supervised and unsupervised evals and kind of a similar term to machine learning use case where supervised evals you know what the right answer should be.\n\n425\n00:39:58,630 --> 00:40:04,550\nIan McGraw: So for like a data set or a previous, you know, run, you can annotate the right answer.\n\n426\n00:40:04,630 --> 00:40:16,070\nIan McGraw: So then the next time you run it's like, did the agent respond Running those are often used in like a batch fashion where you're doing like pre release testing.\n\n427\n00:40:16,070 --> 00:40:23,850\nIan McGraw: You run all the behavior data sets through the agent, make sure it gives you the right answer given the behavior or given the test case.\n\n428\n00:40:24,650 --> 00:40:34,770\nIan McGraw: But there's also unsupervised evals which happen to be more of like your production continuous evals because you've probably not seen the use cases happening in production before.\n\n429\n00:40:34,770 --> 00:40:37,010\nIan McGraw: So you don't know necessarily what the right answer is.\n\n430\n00:40:37,010 --> 00:40:42,890\nIan McGraw: So it's not feasible to write an eval that says, you know, this is the right answer.\n\n431\n00:40:42,890 --> 00:40:44,210\nIan McGraw: Did the agent get the right answer?\n\n432\n00:40:45,480 --> 00:40:51,560\nIan McGraw: So production sense, you're probably running some sort of continuous eval that is unsupervised.\n\n433\n00:40:52,280 --> 00:40:55,600\nIan McGraw: Things like, you know, is the answer relevant to the question being asked?\n\n434\n00:40:55,600 --> 00:40:57,720\nIan McGraw: Is the answer in the format being asked?\n\n435\n00:40:58,200 --> 00:41:09,080\nIan McGraw: Does the answer adhere to company policies like those sorts of kind of qualitative metrics rather than like, is the answer exactly correct?\n\n436\n00:41:10,050 --> 00:41:10,530\nPranav Shikarpur: Gotcha.\n\n437\n00:41:11,250 --> 00:41:13,330\nPranav Shikarpur: But these can also be run in.\n\n438\n00:41:13,570 --> 00:41:15,210\nPranav Shikarpur: But like before it Goes into production.\n\n439\n00:41:15,210 --> 00:41:15,490\nIan McGraw: Right.\n\n440\n00:41:16,130 --> 00:41:17,090\nIan McGraw: Unsupervised ones.\n\n441\n00:41:17,090 --> 00:41:17,290\nIan McGraw: Yeah.\n\n442\n00:41:17,290 --> 00:41:18,370\nIan McGraw: Can be run anytime.\n\n443\n00:41:19,010 --> 00:41:19,850\nPranav Shikarpur: Okay, gotcha.\n\n444\n00:41:19,850 --> 00:41:22,410\nPranav Shikarpur: So you're saying there's two sets of evals that you must run.\n\n445\n00:41:22,410 --> 00:41:24,010\nPranav Shikarpur: One is like the supervised evals.\n\n446\n00:41:24,010 --> 00:41:30,650\nPranav Shikarpur: That's more about like the quantitative numeric stuff where you're like, is it right, how accurate is it?\n\n447\n00:41:30,650 --> 00:41:37,520\nPranav Shikarpur: Is it like, is it like essentially like, you know, aligning with the KPIs and achieve, helping us achieve what we want to achieve.\n\n448\n00:41:37,680 --> 00:41:42,000\nPranav Shikarpur: And the second part is like, is it, is it mean?\n\n449\n00:41:42,240 --> 00:41:43,720\nPranav Shikarpur: It's more the qualitative ones.\n\n450\n00:41:43,720 --> 00:41:44,480\nPranav Shikarpur: Like is it mean?\n\n451\n00:41:44,480 --> 00:41:48,240\nPranav Shikarpur: Is it like answering effectively?\n\n452\n00:41:48,240 --> 00:41:50,520\nPranav Shikarpur: I guess, yeah.\n\n453\n00:41:50,520 --> 00:41:51,280\nPranav Shikarpur: Okay, gotcha.\n\n454\n00:41:51,599 --> 00:41:55,840\nIan McGraw: Essentially the metrics you would care about that aren't exactly the answer.\n\n455\n00:41:56,960 --> 00:41:57,680\nPranav Shikarpur: Gotcha.\n\n456\n00:41:58,240 --> 00:41:58,800\nPranav Shikarpur: Okay.\n\n457\n00:41:59,040 --> 00:42:03,360\nIan McGraw: Okay, so like those things we talked about with the customer service agent, right?\n\n458\n00:42:03,360 --> 00:42:07,560\nIan McGraw: Like is it saying toxic language?\n\n459\n00:42:07,720 --> 00:42:09,400\nIan McGraw: Are people problem injecting it?\n\n460\n00:42:09,480 --> 00:42:15,360\nIan McGraw: Is it, you know, handling the workflows with the expected outcome?\n\n461\n00:42:15,360 --> 00:42:16,040\nIan McGraw: That kind of stuff?\n\n462\n00:42:16,040 --> 00:42:16,440\nPranav Shikarpur: Yeah.\n\n463\n00:42:17,400 --> 00:42:26,440\nPranav Shikarpur: And I think there is, there's a world where you can like kind of build these KPIs for this qualitative measure, you know, from a business angle.\n\n464\n00:42:26,520 --> 00:42:27,960\nPranav Shikarpur: Yeah, right.\n\n465\n00:42:28,360 --> 00:42:30,910\nPranav Shikarpur: So, but yeah, that's, that's, that's pretty interesting.\n\n466\n00:42:30,910 --> 00:42:32,310\nPranav Shikarpur: I didn't not know about that.\n\n467\n00:42:34,390 --> 00:42:34,870\nPranav Shikarpur: Okay.\n\n468\n00:42:34,870 --> 00:42:39,430\nPranav Shikarpur: And okay, I guess I have a, like, just a few more questions.\n\n469\n00:42:41,030 --> 00:42:42,430\nPranav Shikarpur: Is a, is a flywheel?\n\n470\n00:42:42,430 --> 00:42:47,030\nPranav Shikarpur: Would you say it's like a general methodology that people can follow?\n\n471\n00:42:47,430 --> 00:42:48,310\nPranav Shikarpur: I assume it is.\n\n472\n00:42:48,310 --> 00:42:50,710\nPranav Shikarpur: Or is it very implementation specific?\n\n473\n00:42:50,790 --> 00:42:55,190\nPranav Shikarpur: Like does it change for, depending on like where you're implementing it?\n\n474\n00:42:57,120 --> 00:43:00,560\nIan McGraw: I would support the process itself.\n\n475\n00:43:01,920 --> 00:43:03,880\nIan McGraw: The process itself doesn't really change.\n\n476\n00:43:03,880 --> 00:43:06,640\nIan McGraw: Like, it's pretty generic and broad.\n\n477\n00:43:06,800 --> 00:43:16,960\nIan McGraw: But what each like concrete step of the process or the phase will likely look different depending on your agent.\n\n478\n00:43:19,040 --> 00:43:29,810\nIan McGraw: For example, like knowledge retrieval agents are much easier to eval in pre production testing because you can just say like, you know, here's a question.\n\n479\n00:43:29,810 --> 00:43:31,610\nIan McGraw: Did the agent give me the right answer?\n\n480\n00:43:32,170 --> 00:43:44,930\nIan McGraw: But for an agent that's like sending emails or calling customers or you know, closing tickets, I frame those as like mutating agents.\n\n481\n00:43:44,930 --> 00:43:46,890\nIan McGraw: They actually like take action and do things.\n\n482\n00:43:48,370 --> 00:43:57,490\nIan McGraw: You can't really evaluate those because then they like need to be able to go take actions without mocking essentially everything it would interact with.\n\n483\n00:43:58,130 --> 00:43:59,930\nIan McGraw: So those evals might look a little different.\n\n484\n00:43:59,930 --> 00:44:03,730\nIan McGraw: And how you actually simulate usage probably looks a little different.\n\n485\n00:44:04,850 --> 00:44:06,930\nPranav Shikarpur: Gotcha, Gotcha.\n\n486\n00:44:08,210 --> 00:44:08,810\nPranav Shikarpur: Okay.\n\n487\n00:44:08,810 --> 00:44:13,610\nPranav Shikarpur: And in these, so I know you said you touched on this like mutating agents.\n\n488\n00:44:13,610 --> 00:44:17,570\nPranav Shikarpur: I assume these are like agents not with just like read only access Right.\n\n489\n00:44:18,290 --> 00:44:19,730\nPranav Shikarpur: Allows you to do multiple stuff.\n\n490\n00:44:23,890 --> 00:44:24,930\nPranav Shikarpur: Is there some more?\n\n491\n00:44:24,930 --> 00:44:34,290\nPranav Shikarpur: Like, like, I know there's like a risk security factor of it that people talk about a lot, but is there like something else you need to consider while you're building evals?\n\n492\n00:44:35,810 --> 00:44:44,050\nPranav Shikarpur: Outside of just, you know, making sure it's accurately meeting our KPIs, are there any like evals for risk and security that you build in?\n\n493\n00:44:44,710 --> 00:44:46,550\nPranav Shikarpur: Is that not relevant.\n\n494\n00:44:49,350 --> 00:44:49,750\nIan McGraw: Security?\n\n495\n00:44:52,710 --> 00:45:02,390\nIan McGraw: My opinion on this is that security shouldn't be left up to like non deterministic evals to detect.\n\n496\n00:45:05,430 --> 00:45:18,720\nIan McGraw: Like that should be baked in like the LLM should only ever see information and have tools that it is allowed to use.\n\n497\n00:45:18,960 --> 00:45:28,400\nIan McGraw: Like you should not give it a tool to like, you know, update any user in the database and then give the LLM the power to insert whatever user ID it wants.\n\n498\n00:45:28,400 --> 00:45:28,720\nIan McGraw: Right?\n\n499\n00:45:28,800 --> 00:45:29,480\nPranav Shikarpur: Yeah, yeah.\n\n500\n00:45:29,480 --> 00:45:46,550\nIan McGraw: But you should create a tool that is scoped to the user interacting with the LLM in that space specific context and then the user ID is passed in via like deterministic code in that session gets a tool that scope to the user using the tool.\n\n501\n00:45:47,510 --> 00:45:48,390\nPranav Shikarpur: That makes sense.\n\n502\n00:45:49,190 --> 00:45:58,630\nIan McGraw: Regardless of how you set up evals or guardrails, there's always some chance that like you'll be able to prompt inject your way around it and you can say no, my user ID is Pranav's user id.\n\n503\n00:45:58,710 --> 00:45:59,070\nIan McGraw: Yeah.\n\n504\n00:45:59,070 --> 00:46:00,950\nIan McGraw: And then LLM will just like do it.\n\n505\n00:46:01,190 --> 00:46:08,340\nIan McGraw: So my take on security is that it needs to be handled outside of LLMs entirely.\n\n506\n00:46:08,580 --> 00:46:12,020\nPranav Shikarpur: Evals is not a good place to build security.\n\n507\n00:46:12,260 --> 00:46:12,980\nPranav Shikarpur: Gotcha.\n\n508\n00:46:14,580 --> 00:46:16,020\nPranav Shikarpur: Yeah, makes sense.\n\n509\n00:46:16,660 --> 00:46:18,820\nPranav Shikarpur: And okay, I have last two questions.\n\n510\n00:46:18,820 --> 00:46:19,980\nPranav Shikarpur: One is like, what's.\n\n511\n00:46:19,980 --> 00:46:22,580\nPranav Shikarpur: How do you differentiate a good eval from a bad eval?\n\n512\n00:46:24,180 --> 00:46:30,180\nIan McGraw: Yeah, I think it comes down to maybe two or three things.\n\n513\n00:46:30,180 --> 00:46:32,300\nIan McGraw: The first one I'm thinking of is like, is it important?\n\n514\n00:46:32,940 --> 00:46:35,620\nIan McGraw: Similar to like alerts in production.\n\n515\n00:46:35,620 --> 00:46:35,820\nIan McGraw: Right.\n\n516\n00:46:35,820 --> 00:46:40,940\nIan McGraw: If this alert fires and no one does anything about it's not important, it's just noise.\n\n517\n00:46:41,580 --> 00:46:43,340\nIan McGraw: So like is the signal valuable?\n\n518\n00:46:43,660 --> 00:46:44,900\nIan McGraw: Is probably the first thing.\n\n519\n00:46:44,900 --> 00:46:48,060\nIan McGraw: Like does it influence a KPI that matters.\n\n520\n00:46:49,820 --> 00:47:03,670\nIan McGraw: The second one is then trying to think how to phrase this, but essentially in the structure of the eval in Arthur's platform, by default all evals are just pass fail.\n\n521\n00:47:04,950 --> 00:47:12,950\nIan McGraw: But a lot of people want to make like a score on you know, 0 to 10 how toxic or whatever this response is.\n\n522\n00:47:14,230 --> 00:47:24,290\nIan McGraw: But then the problem with that is you've essentially now put the burden of deciding like what is considered too toxic on the person doing the analysis.\n\n523\n00:47:24,770 --> 00:47:25,890\nPranav Shikarpur: Yeah, yeah.\n\n524\n00:47:26,130 --> 00:47:31,130\nIan McGraw: So it's important to have like pass fail, decisions being made as the agents, like that.\n\n525\n00:47:31,130 --> 00:47:37,730\nIan McGraw: That's what you want the automated evals to do, is to, like, make decisions like, is this bad behavior or good behavior?\n\n526\n00:47:38,370 --> 00:47:42,290\nIan McGraw: And if all they're doing is scoring, you're just pushing that upstream.\n\n527\n00:47:42,930 --> 00:47:49,680\nIan McGraw: Yeah, I would say that's another signal is eval should be pass fail and be very clear, like, is this good or is this bad?\n\n528\n00:47:49,760 --> 00:47:52,160\nIan McGraw: So then users can pay attention to the bad ones.\n\n529\n00:47:52,800 --> 00:47:54,240\nPranav Shikarpur: Gotcha, gotcha.\n\n530\n00:47:54,640 --> 00:47:54,960\nPranav Shikarpur: So.\n\n531\n00:47:54,960 --> 00:48:04,240\nPranav Shikarpur: So if you're saying if there's like a score that you're getting out of it, like, you just need, like, more evals to make it pass fail, Right?\n\n532\n00:48:04,640 --> 00:48:05,520\nPranav Shikarpur: Okay, gotcha.\n\n533\n00:48:05,520 --> 00:48:06,000\nIan McGraw: Gotcha.\n\n534\n00:48:06,080 --> 00:48:09,280\nIan McGraw: Yeah, because it's like, well, it's 5 too toxic.\n\n535\n00:48:09,280 --> 00:48:10,800\nIan McGraw: It's 7 too toxic.\n\n536\n00:48:10,800 --> 00:48:13,840\nIan McGraw: Like, I have some notion that it's a little toxic.\n\n537\n00:48:13,840 --> 00:48:15,850\nIan McGraw: But, like, you know, the.\n\n538\n00:48:15,850 --> 00:48:20,730\nIan McGraw: The eval should have the knowledge baked in of, like, what is toxic and what is not.\n\n539\n00:48:22,090 --> 00:48:22,730\nPranav Shikarpur: That's.\n\n540\n00:48:22,810 --> 00:48:23,930\nPranav Shikarpur: That's very valuable.\n\n541\n00:48:25,370 --> 00:48:26,010\nPranav Shikarpur: And like.\n\n542\n00:48:26,490 --> 00:48:27,450\nPranav Shikarpur: So last question.\n\n543\n00:48:28,250 --> 00:48:30,130\nPranav Shikarpur: Have you seen companies get evals?\n\n544\n00:48:30,130 --> 00:48:30,490\nPranav Shikarpur: Right.\n\n545\n00:48:31,690 --> 00:48:33,130\nPranav Shikarpur: Are there situations if.\n\n546\n00:48:33,370 --> 00:48:38,970\nPranav Shikarpur: Where you've seen companies in certain industries where they've gotten evals?\n\n547\n00:48:39,450 --> 00:48:39,850\nPranav Shikarpur: Right.\n\n548\n00:48:39,930 --> 00:48:51,400\nPranav Shikarpur: And if you could, like, probably potentially, like, walk over a little bit of their use case and you could talk about up solve here, a little bit of their use case and, like, what they did?\n\n549\n00:48:51,400 --> 00:48:51,720\nPranav Shikarpur: Right.\n\n550\n00:48:52,520 --> 00:48:53,000\nPranav Shikarpur: Yeah.\n\n551\n00:48:53,320 --> 00:48:56,120\nIan McGraw: Do you mean, like, outside of Arthur?\n\n552\n00:48:56,120 --> 00:48:57,800\nPranav Shikarpur: Like, outside of Arthur, Yeah.\n\n553\n00:48:57,800 --> 00:48:58,640\nPranav Shikarpur: You could talk about upsol.\n\n554\n00:48:58,640 --> 00:49:03,320\nPranav Shikarpur: I mean, we're gonna have hopefully the case study out before this blog goes live.\n\n555\n00:49:03,560 --> 00:49:15,520\nIan McGraw: So I guess asking is like, are you curious about companies that have implemented evals correctly without Arthur, or do you want to hear about people like upsolve that have used Arthur to implement eval?\n\n556\n00:49:17,040 --> 00:49:23,280\nPranav Shikarpur: I'd say the former and then like, a little bit of the latter, but, like, more of the former.\n\n557\n00:49:23,760 --> 00:49:24,240\nPranav Shikarpur: Yeah.\n\n558\n00:49:25,840 --> 00:49:30,480\nIan McGraw: I mean, to be honest, I haven't seen many companies implement evals.\n\n559\n00:49:31,760 --> 00:49:35,120\nIan McGraw: Usually it's like a lot of people we're talking to are like, yeah, we need this.\n\n560\n00:49:35,930 --> 00:49:36,930\nIan McGraw: We don't really have it.\n\n561\n00:49:36,930 --> 00:49:43,210\nIan McGraw: Or like, we have some script that, like, runs a couple test cases through a prompt and that's it.\n\n562\n00:49:43,290 --> 00:49:43,770\nPranav Shikarpur: Thanks.\n\n563\n00:49:44,890 --> 00:49:51,050\nIan McGraw: See, I really don't have Gotcha a concrete example of a company I've heard of.\n\n564\n00:49:53,370 --> 00:50:00,090\nIan McGraw: I guess, like, I know OpenAI and ChatGPT have evals and guardrails and content filters baked in.\n\n565\n00:50:00,980 --> 00:50:01,460\nPranav Shikarpur: Mm.\n\n566\n00:50:03,700 --> 00:50:05,140\nIan McGraw: But, yeah, I haven't.\n\n567\n00:50:05,780 --> 00:50:10,500\nIan McGraw: Most of the people I've heard of are like, oh, yeah, we hacked something together in house and that's it.\n\n568\n00:50:11,060 --> 00:50:12,260\nPranav Shikarpur: Yeah, yeah.\n\n569\n00:50:13,300 --> 00:50:18,660\nIan McGraw: But we're talking with a lot of early stage folks so it's like very clear to them, like, oh, this is going to be an issue.\n\n570\n00:50:19,140 --> 00:50:21,700\nIan McGraw: Yeah, it's not there yet for sure.\n\n571\n00:50:21,780 --> 00:50:22,420\nPranav Shikarpur: For sure.\n\n572\n00:50:23,460 --> 00:50:25,860\nPranav Shikarpur: And I assume later companies haven't gotten to it yet.\n\n573\n00:50:25,860 --> 00:50:27,860\nPranav Shikarpur: Like most of the enterprises and giants.\n\n574\n00:50:28,660 --> 00:50:34,300\nIan McGraw: I think most of the enterprises are still like in the early phases of like, how can we bring this technology in?\n\n575\n00:50:34,300 --> 00:50:42,740\nIan McGraw: There was one company, Gardner Health, I went to a AI night of and they're using LLMs for their customer support bot.\n\n576\n00:50:43,380 --> 00:50:51,220\nIan McGraw: But they've only kind of what I mentioned earlier, given it like the low hanging fruit, essentially it can actually issue refunds.\n\n577\n00:50:51,220 --> 00:50:57,630\nIan McGraw: It basically is like, oh, you know, I don't even know, like have a question about your account.\n\n578\n00:50:57,630 --> 00:50:59,270\nIan McGraw: Like, let me look up the answer.\n\n579\n00:50:59,270 --> 00:51:00,110\nIan McGraw: Type stuff.\n\n580\n00:51:00,190 --> 00:51:00,990\nPranav Shikarpur: Yeah, yeah.\n\n581\n00:51:01,470 --> 00:51:05,150\nIan McGraw: And it's all very explicit workflows they have coded.\n\n582\n00:51:05,230 --> 00:51:08,110\nIan McGraw: So the LLM basically routes to a predefined workflow.\n\n583\n00:51:08,110 --> 00:51:11,510\nIan McGraw: The workflow like walks through the steps and then exits.\n\n584\n00:51:11,510 --> 00:51:15,190\nIan McGraw: There's no agent icness to the customer support bot.\n\n585\n00:51:15,190 --> 00:51:20,190\nIan McGraw: So it's not like figuring out like doesn't have access to systems and stuff like that.\n\n586\n00:51:20,190 --> 00:51:25,320\nIan McGraw: It's just kind of a text router among different steps in a predetermined workflow.\n\n587\n00:51:25,720 --> 00:51:26,440\nPranav Shikarpur: Gotcha.\n\n588\n00:51:26,680 --> 00:51:28,280\nPranav Shikarpur: Cool, cool, cool.\n\n589\n00:51:28,520 --> 00:51:31,720\nPranav Shikarpur: And yeah, that was really great.\n\n590\n00:51:31,880 --> 00:51:33,000\nPranav Shikarpur: Thanks for all of that.\n\n591\n00:51:33,240 --> 00:51:36,680\nPranav Shikarpur: And lastly, how many evals is too many evals?\n\n592\n00:51:37,080 --> 00:51:37,880\nPranav Shikarpur: Is there a number?\n\n593\n00:51:41,320 --> 00:51:42,200\nIan McGraw: I think there is.\n\n594\n00:51:42,760 --> 00:51:45,040\nPranav Shikarpur: Oh, there is again.\n\n595\n00:51:45,040 --> 00:51:55,540\nIan McGraw: It's like back to the signal, you know, if you're, I guess if you have a bunch of like very well tuned evals, it's probably fine.\n\n596\n00:51:55,540 --> 00:52:02,500\nIan McGraw: But I imagine, you know, most people will be in the boat where they're creating a ton of evals and they're all failing.\n\n597\n00:52:02,500 --> 00:52:10,340\nIan McGraw: It's like I would recommend focusing on your top five and then once those are good, you know, add another few.\n\n598\n00:52:11,780 --> 00:52:15,500\nIan McGraw: But the point is you want your evals to be actionable.\n\n599\n00:52:16,540 --> 00:52:22,780\nIan McGraw: So having like tons and tons of evals I think is probably a bit of like over signal.\n\n600\n00:52:23,980 --> 00:52:24,620\nPranav Shikarpur: Gotcha.\n\n601\n00:52:24,780 --> 00:52:25,580\nPranav Shikarpur: That makes sense.\n\n602\n00:52:25,740 --> 00:52:26,220\nIan McGraw: Yeah.\n\n603\n00:52:27,180 --> 00:52:28,100\nPranav Shikarpur: Cool, cool.\n\n604\n00:52:28,100 --> 00:52:28,860\nPranav Shikarpur: Thanks a lot.\n\n605\n00:52:30,380 --> 00:52:40,220\nPranav Shikarpur: I'm gonna take this up, try to, I'm gonna transcribe this, try to, you know, hack it together and find like a good messaging cook for this blog.\n\n606\n00:52:40,680 --> 00:52:51,880\nPranav Shikarpur: And then I'll share a draft with you on Monday and it'll be a pretty short blog, but about 80 the flywheel primarily.\n\n607\n00:52:52,840 --> 00:52:56,360\nPranav Shikarpur: And yeah, we'll love your feedback then when I share it with you.\n\n608\n00:52:56,360 --> 00:52:56,720\nPranav Shikarpur: Thanks.\n\n609\n00:52:56,720 --> 00:52:57,960\nIan McGraw: Cool man, sounds good.\n\n610\n00:52:58,600 --> 00:52:59,560\nIan McGraw: Thanks for the chat.\n\n611\n00:52:59,640 --> 00:53:00,040\nPranav Shikarpur: Okay.\n\n612\n00:53:00,040 --> 00:53:00,760\nPranav Shikarpur: I'll talk to you later.\n\n613\n00:53:01,320 --> 00:53:02,040\nPranav Shikarpur: Yeah, for sure.\n\n",
  "type": "release_notes",
  "original_format": ".txt",
  "created_at": "2025-11-19T21:15:42.507811Z"
}
